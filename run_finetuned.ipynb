{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from util import task_to_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(use_finetuned):\n",
    "    peft_model_id = \"finetuned-models/Starling-LM-7B-alpha-finetuned\"\n",
    "\n",
    "    config = PeftConfig.from_pretrained(peft_model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, \n",
    "                                                        quantization_config=bnb_config, \n",
    "                                                        return_dict=True, \n",
    "                                                        load_in_4bit=True, \n",
    "                                                        device_map=\"auto\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "    # Load the Lora model\n",
    "    if use_finetuned:\n",
    "        model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model, tokenizer, max_new_tokens=1024, temperature=0.5):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    token_length = len(input_ids[\"input_ids\"][0])\n",
    "    if token_length > 8192:\n",
    "        print(\"Input too long: \", token_length)\n",
    "        return prompt + \"\\n\\nInput too long. Please try again.\"\n",
    "    print(\"token length:\", token_length)\n",
    "    outputs = model.generate(**input_ids, do_sample=True, temperature=temperature, pad_token_id=tokenizer.eos_token_id, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d21716826c4ceca32c34b346a8566a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c97c0139.json token length: 5775\n",
      "ea9794b1.json token length: 2667\n",
      "5d2a5c43.json token length: 1434\n",
      "fea12743.json token length: 3768\n",
      "ae58858e.json token length: 2187\n",
      "0f63c0b9.json token length: 6162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e99362f0.json token length: 2556\n",
      "195ba7dc.json token length: 1422\n",
      "f3cdc58f.json token length: 2172\n",
      "a8610ef7.json token length: 1059\n",
      "84db8fc4.json token length: 2787\n",
      "4b6b68e5.json token length: 7986\n",
      "ff72ca3e.json token length: 4173\n",
      "8ee62060.json token length: 2988\n",
      "0b17323b.json token length: 3432\n",
      "c074846d.json token length: 1449\n",
      "e345f17b.json token length: 759\n",
      "50aad11f.json token length: 2586\n",
      "e4075551.json token length: 4662\n",
      "66e6c45b.json token length: 297\n",
      "358ba94e.json token length: 4791\n",
      "d017b73f.json token length: 852\n",
      "4c177718.json token length: 5082\n",
      "b7999b51.json token length: 2769\n",
      "3979b1a8.json token length: 882\n",
      "bf32578f.json token length: 1296\n",
      "d19f7514.json token length: 1095\n",
      "b0722778.json token length: 900\n",
      "136b0064.json token length: 3105\n",
      "5b526a93.json token length: 5997\n",
      "ef26cbf6.json token length: 1212\n",
      "e633a9e5.json token length: 405\n",
      "62ab2642.json token length: 1962\n",
      "73c3b0d8.json token length: 1629\n",
      "08573cc6.json token length: 2895\n",
      "c48954c1.json token length: 909\n",
      "31d5ba1a.json token length: 867\n",
      "59341089.json token length: 654\n",
      "00576224.json token length: 309\n",
      "48131b3c.json token length: 555\n",
      "60a26a3e.json token length: 3801\n",
      "4e469f39.json token length: 2172\n",
      "b1fc8b8e.json token length: 1125\n",
      "2c737e39.json token length: 2526\n",
      "992798f6.json token length: 5847\n",
      "e1d2900e.json Input too long:  14352\n",
      "903d1b4a.json token length: 6999\n",
      "af24b4cc.json token length: 1332\n",
      "551d5bf1.json Input too long:  9717\n",
      "b457fec5.json token length: 7905\n",
      "50a16a69.json token length: 3450\n",
      "7953d61e.json token length: 1350\n",
      "817e6c09.json token length: 2853\n",
      "1da012fc.json token length: 5670\n",
      "310f3251.json token length: 1755\n",
      "7d18a6fb.json token length: 3777\n",
      "bf699163.json token length: 2391\n",
      "917bccba.json token length: 3096\n",
      "184a9768.json Input too long:  9960\n",
      "94133066.json token length: 7002\n",
      "256b0a75.json Input too long:  11262\n",
      "e681b708.json Input too long:  11634\n",
      "ce8d95cc.json token length: 2331\n",
      "9772c176.json Input too long:  8553\n",
      "ed74f2f2.json token length: 1224\n",
      "d282b262.json token length: 4797\n",
      "b942fd60.json token length: 2973\n",
      "fd4b2b02.json Input too long:  9606\n",
      "bf89d739.json token length: 5535\n",
      "f5aa3634.json token length: 2496\n",
      "ad7e01d0.json token length: 2334\n",
      "506d28a5.json token length: 1002\n",
      "27a77e38.json token length: 813\n",
      "d492a647.json token length: 3084\n",
      "72a961c9.json token length: 2394\n",
      "fafd9572.json token length: 2577\n",
      "67c52801.json token length: 1722\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "model, tokenizer = create_model(use_finetuned=True)\n",
    "\n",
    "for task in tqdm(os.listdir(\"data/evaluation\")):\n",
    "    if os.path.exists(f\"fine_tuned_results/evaluation/{task.replace('.json', '.txt')}\"):\n",
    "        continue\n",
    "    prompt, output = task_to_prompt(\"data/evaluation/\" + task)\n",
    "    print(f\"{task}\", end=\" \")\n",
    "    full_prompt = f\"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
    "    output = generate_response(full_prompt, model=model, tokenizer=tokenizer, max_new_tokens=2048, temperature=0.5)\n",
    "    with open(f\"fine_tuned_results/evaluation/{task.replace('.json', '.txt')}\", \"w\") as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc5de831b22465da6e2f7298f968dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "model, tokenizer = create_model(use_finetuned=True)\n",
    "for task in tqdm(os.listdir(\"data/training\")):\n",
    "    if os.path.exists(f\"fine_tuned_results/training/{task.replace('.json', '.txt')}\"):\n",
    "        continue\n",
    "    prompt, output = task_to_prompt(\"data/training/\" + task)\n",
    "    print(f\"{task}\", end=\" \")\n",
    "    full_prompt = f\"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
    "    output = generate_response(full_prompt, model=model, tokenizer=tokenizer, max_new_tokens=2048, temperature=0.5)\n",
    "    with open(f\"fine_tuned_results/training/{task.replace('.json', '.txt')}\", \"w\") as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Concept ARC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e96f737e7b241d986f4ea2db9256913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtendToBoundary2.json token length: 5220\n",
      "ExtendToBoundary6.json token length: 2199\n",
      "ExtendToBoundary3.json token length: 2550\n",
      "ExtendToBoundary7.json token length: 1749\n",
      "ExtendToBoundary9.json token length: 4809\n",
      "ExtendToBoundary1.json token length: 1353\n",
      "ExtendToBoundary5.json token length: 1476\n",
      "ExtendToBoundary10.json token length: 2097\n",
      "ExtendToBoundary4.json token length: 1059\n",
      "ExtendToBoundary8.json token length: 2583\n",
      "ExtendToBoundaryMinimal.json token length: 1059\n",
      "MoveToBoundary8.json token length: 2901\n",
      "MoveToBoundary10.json token length: 1827\n",
      "MoveToBoundary4.json token length: 1557\n",
      "MoveToBoundary5.json token length: 1557\n",
      "MoveToBoundary1.json token length: 1305\n",
      "MoveToBoundary9.json token length: 2025\n",
      "MoveToBoundary7.json token length: 2565\n",
      "MoveToBoundary3.json token length: 1557\n",
      "MoveToBoundary6.json token length: 1059\n",
      "MoveToBoundary2.json token length: 2172\n",
      "MoveToBoundaryMinimal.json token length: 1557\n",
      "ExtractObjects7.json token length: 1182\n",
      "ExtractObjects3.json token length: 2160\n",
      "ExtractObjects6.json token length: 1254\n",
      "ExtractObjects2.json token length: 2481\n",
      "ExtractObjects4.json token length: 1812\n",
      "ExtractObjects8.json token length: 1101\n",
      "ExtractObjects10.json token length: 1359\n",
      "ExtractObjects9.json token length: 1443\n",
      "ExtractObjects5.json token length: 2367\n",
      "ExtractObjectsMinimal.json token length: 1614\n",
      "ExtractObjects1.json token length: 1437\n",
      "HorizontalVertical10.json token length: 1557\n",
      "HorizontalVertical7.json token length: 2172\n",
      "HorizontalVertical3.json token length: 3024\n",
      "HorizontalVertical6.json token length: 4188\n",
      "HorizontalVertical2.json token length: 2433\n",
      "HorizontalVertical4.json token length: 4167\n",
      "HorizontalVertical8.json token length: 4680\n",
      "HorizontalVerticalMinimal.json token length: 1740\n",
      "HorizontalVertical9.json token length: 597\n",
      "HorizontalVertical5.json token length: 2172\n",
      "HorizontalVertical1.json token length: 2805\n",
      "InsideOutside6.json token length: 2874\n",
      "InsideOutside2.json token length: 2787\n",
      "InsideOutside7.json token length: 1194\n",
      "InsideOutside3.json token length: 2787\n",
      "InsideOutsideMinimal.json token length: 2172\n",
      "InsideOutside9.json token length: 1317\n",
      "InsideOutside10.json token length: 2217\n",
      "InsideOutside5.json token length: 4923\n",
      "InsideOutside1.json token length: 1296\n",
      "InsideOutside4.json token length: 5211\n",
      "InsideOutside8.json token length: 1938\n",
      "Count5.json token length: 693\n",
      "Count1.json token length: 1314\n",
      "Count9.json token length: 1197\n",
      "Count8.json token length: 1416\n",
      "Count4.json token length: 1518\n",
      "Count6.json token length: 1437\n",
      "Count2.json token length: 3324\n",
      "Count7.json token length: 1419\n",
      "Count10.json token length: 1062\n",
      "Count3.json token length: 1530\n",
      "CountMinimal.json token length: 531\n",
      "CleanUp4.json token length: 3489\n",
      "CleanUpMinimal.json token length: 1245\n",
      "CleanUp8.json token length: 1557\n",
      "CleanUp9.json token length: 597\n",
      "CleanUp5.json token length: 2001\n",
      "CleanUp1.json token length: 1740\n",
      "CleanUp7.json token length: 1773\n",
      "CleanUp3.json token length: 2697\n",
      "CleanUp10.json token length: 597\n",
      "CleanUp6.json token length: 1857\n",
      "CleanUp2.json token length: 1464\n",
      "AboveBelow10.json token length: 1890\n",
      "AboveBelow7.json token length: 2325\n",
      "AboveBelow3.json token length: 1635\n",
      "AboveBelow6.json token length: 1533\n",
      "AboveBelowMinimal.json token length: 786\n",
      "AboveBelow2.json token length: 5082\n",
      "AboveBelow8.json token length: 2712\n",
      "AboveBelow4.json token length: 1629\n",
      "AboveBelow5.json token length: 1221\n",
      "AboveBelow1.json token length: 3108\n",
      "AboveBelow9.json token length: 2487\n",
      "Order1.json token length: 2937\n",
      "Order5.json token length: 1947\n",
      "Order9.json token length: 867\n",
      "Order8.json token length: 897\n",
      "Order4.json token length: 1617\n",
      "Order2.json token length: 1617\n",
      "Order6.json token length: 1689\n",
      "OrderMinimal.json token length: 828\n",
      "Order3.json token length: 1191\n",
      "Order7.json token length: 2718\n",
      "Order10.json token length: 1782\n",
      "TopBottom3D1.json token length: 1416\n",
      "TopBottom3D5.json token length: 1458\n",
      "TopBottom3D9.json token length: 2940\n",
      "TopBottom3D10.json token length: 3078\n",
      "TopBottom3D8.json token length: 1059\n",
      "TopBottom3D4.json token length: 1815\n",
      "TopBottom3D2.json token length: 1101\n",
      "TopBottom3D6.json token length: 594\n",
      "TopBottom3DMinimal.json token length: 1017\n",
      "TopBottom3D3.json token length: 1416\n",
      "TopBottom3D7.json token length: 2256\n",
      "Copy4.json token length: 3096\n",
      "Copy8.json token length: 2403\n",
      "Copy10.json token length: 2733\n",
      "Copy9.json token length: 2214\n",
      "Copy1.json token length: 495\n",
      "Copy5.json token length: 681\n",
      "Copy3.json token length: 2643\n",
      "Copy7.json token length: 1305\n",
      "Copy2.json token length: 2265\n",
      "CopyMinimal.json token length: 510\n",
      "Copy6.json token length: 846\n",
      "CompleteShape8.json token length: 1557\n",
      "CompleteShape4.json token length: 1557\n",
      "CompleteShape5.json token length: 597\n",
      "CompleteShape10.json token length: 3783\n",
      "CompleteShape1.json token length: 1425\n",
      "CompleteShapeMinimal.json token length: 1467\n",
      "CompleteShape9.json token length: 2181\n",
      "CompleteShape7.json token length: 597\n",
      "CompleteShape3.json token length: 1557\n",
      "CompleteShape6.json token length: 597\n",
      "CompleteShape2.json token length: 990\n",
      "SameDifferent2.json token length: 2709\n",
      "SameDifferent6.json token length: 2580\n",
      "SameDifferent3.json token length: 1968\n",
      "SameDifferent7.json token length: 3339\n",
      "SameDifferent1.json token length: 1905\n",
      "SameDifferent5.json token length: 1632\n",
      "SameDifferent10.json token length: 2781\n",
      "SameDifferent9.json token length: 2787\n",
      "SameDifferent8.json token length: 1770\n",
      "SameDifferentMinimal.json token length: 2787\n",
      "SameDifferent4.json token length: 1557\n",
      "Center7.json token length: 525\n",
      "Center3.json token length: 2808\n",
      "Center6.json token length: 3807\n",
      "Center2.json token length: 153\n",
      "Center10.json token length: 1095\n",
      "Center8.json token length: 2784\n",
      "Center4.json token length: 1053\n",
      "CenterMinimal.json token length: 981\n",
      "Center5.json token length: 2019\n",
      "Center1.json token length: 1314\n",
      "Center9.json token length: 1497\n",
      "FilledNotFilled6.json token length: 1398\n",
      "FilledNotFilled2.json token length: 1383\n",
      "FilledNotFilledMinimal.json token length: 1416\n",
      "FilledNotFilled7.json token length: 2214\n",
      "FilledNotFilled3.json token length: 1290\n",
      "FilledNotFilled9.json token length: 3549\n",
      "FilledNotFilled5.json token length: 1665\n",
      "FilledNotFilled1.json token length: 1281\n",
      "FilledNotFilled10.json token length: 3819\n",
      "FilledNotFilled4.json token length: 3039\n",
      "FilledNotFilled8.json token length: 2019\n",
      "TopBottom2D2.json token length: 885\n",
      "TopBottom2D6.json token length: 849\n",
      "TopBottom2D3.json token length: 1683\n",
      "TopBottom2DMinimal.json token length: 828\n",
      "TopBottom2D7.json token length: 1314\n",
      "TopBottom2D9.json token length: 1059\n",
      "TopBottom2D1.json token length: 1194\n",
      "TopBottom2D5.json token length: 2172\n",
      "TopBottom2D10.json token length: 1539\n",
      "TopBottom2D4.json token length: 2862\n",
      "TopBottom2D8.json token length: 2172\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "model, tokenizer = create_model(use_finetuned=True)\n",
    "\n",
    "for subdir, dirs, files in tqdm(os.walk(\"data/ConceptARC/\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            if os.path.exists(f\"fine_tuned_results/ConceptARC/{file.replace('.json', '.txt')}\"):\n",
    "                continue\n",
    "            concepts = subdir.replace('data', 'fine_tuned_results')\n",
    "            if not os.path.exists(concepts):\n",
    "                os.mkdir(concepts)\n",
    "            prompt, output = task_to_prompt(os.path.join(subdir, file))\n",
    "            print(f\"{file}\", end=\" \")\n",
    "            full_prompt = f\"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
    "            output = generate_response(full_prompt, model=model, tokenizer=tokenizer, max_new_tokens=2048, temperature=0.5)\n",
    "            with open(f\"{concepts}/{file.replace('.json', '.txt')}\", \"w\") as f:\n",
    "                f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e227d7f78f4c8e8aaddd369ecb719d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">tqdm.notebook</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> tqdm                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">os</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 4 model, tokenizer = create_model(use_finetuned=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> task <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tqdm(os.listdir(<span style=\"color: #808000; text-decoration-color: #808000\">\"data/evaluation\"</span>)):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># if os.path.exists(f\"basemodel_results/evaluation/{task.replace('.json', '.txt')}\")</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">create_model</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>peft_model_id = <span style=\"color: #808000; text-decoration-color: #808000\">\"finetuned-models/Starling-LM-7B-alpha-finetuned\"</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>config = PeftConfig.from_pretrained(peft_model_id)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   │   │   │   </span>quantization_config=bnb_config,     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   │   │   │   </span>return_dict=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   │   │   │   │   </span>load_in_4bit=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/models/auto/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">auto</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_factory.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">566</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">563 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">564 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(config) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping.keys():                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">565 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>model_class = _get_model_class(config, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._model_mapping)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>566 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_class.from_pretrained(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">568 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">569 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3742</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3739 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>mismatched_keys,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3740 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>offload_index,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3741 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>error_msgs,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3742 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>) = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._load_pretrained_model(                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3743 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>model,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3744 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>state_dict,                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>loaded_state_dict_keys,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># XXX: rename?</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4161</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_pretrained_model</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   │   </span>model_to_load, key, <span style=\"color: #808000; text-decoration-color: #808000\">\"cpu\"</span>, torch.empty(*param.si  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   │   </span>)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>4161 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>new_error_msgs, offload_index, state_dict_index = _load_state_di  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>model_to_load,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>state_dict,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>loaded_keys,                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">744</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_state_dict_into_meta_model</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 741 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"dtype\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(inspect.signature(set_module_tensor_to_device).parame  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 742 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>set_module_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"dtype\"</span>] = torch.float32                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 743 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 744 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param = param.to(dtype)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 745 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 746 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># For compatibility with PyTorch load_state_dict which converts state dict dtype</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 747 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m4\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mtqdm\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mnotebook\u001b[0m \u001b[94mimport\u001b[0m tqdm                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mos\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 4 model, tokenizer = create_model(use_finetuned=\u001b[94mFalse\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[94mfor\u001b[0m task \u001b[95min\u001b[0m tqdm(os.listdir(\u001b[33m\"\u001b[0m\u001b[33mdata/evaluation\u001b[0m\u001b[33m\"\u001b[0m)):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# if os.path.exists(f\"basemodel_results/evaluation/{task.replace('.json', '.txt')}\")\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mcreate_model\u001b[0m:\u001b[94m5\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m│   \u001b[0mpeft_model_id = \u001b[33m\"\u001b[0m\u001b[33mfinetuned-models/Starling-LM-7B-alpha-finetuned\u001b[0m\u001b[33m\"\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0mconfig = PeftConfig.from_pretrained(peft_model_id)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5 \u001b[2m│   \u001b[0mmodel = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mquantization_config=bnb_config,     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mreturn_dict=\u001b[94mTrue\u001b[0m,                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mload_in_4bit=\u001b[94mTrue\u001b[0m,                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/models/auto/\u001b[0m\u001b[1;33mauto\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m_factory.py\u001b[0m:\u001b[94m566\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(config) \u001b[95min\u001b[0m \u001b[96mcls\u001b[0m._model_mapping.keys():                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_class = _get_model_class(config, \u001b[96mcls\u001b[0m._model_mapping)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m model_class.from_pretrained(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path, *model_args, config=config, **hub_kwargs,   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m3742\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3739 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmismatched_keys,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3740 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moffload_index,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3741 \u001b[0m\u001b[2m│   │   │   │   \u001b[0merror_msgs,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3742 \u001b[2m│   │   │   \u001b[0m) = \u001b[96mcls\u001b[0m._load_pretrained_model(                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3743 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3744 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mstate_dict,                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3745 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mloaded_state_dict_keys,  \u001b[2m# XXX: rename?\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m4161\u001b[0m in \u001b[92m_load_pretrained_model\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4158 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   \u001b[0mmodel_to_load, key, \u001b[33m\"\u001b[0m\u001b[33mcpu\u001b[0m\u001b[33m\"\u001b[0m, torch.empty(*param.si  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4159 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   \u001b[0m)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4160 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4161 \u001b[2m│   │   │   │   │   │   \u001b[0mnew_error_msgs, offload_index, state_dict_index = _load_state_di  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4162 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mmodel_to_load,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4163 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mstate_dict,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4164 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mloaded_keys,                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/cta/users/tuna/Desktop/ARC-SDP/.venv/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.p\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m744\u001b[0m in \u001b[92m_load_state_dict_into_meta_model\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 741 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mdtype\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m \u001b[96mlist\u001b[0m(inspect.signature(set_module_tensor_to_device).parame  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 742 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mset_module_kwargs[\u001b[33m\"\u001b[0m\u001b[33mdtype\u001b[0m\u001b[33m\"\u001b[0m] = torch.float32                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 743 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 744 \u001b[2m│   │   │   │   \u001b[0mparam = param.to(dtype)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 745 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 746 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# For compatibility with PyTorch load_state_dict which converts state dict dtype\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 747 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dtype \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "model, tokenizer = create_model(use_finetuned=False)\n",
    "\n",
    "for task in tqdm(os.listdir(\"data/evaluation\")):\n",
    "    # if os.path.exists(f\"basemodel_results/evaluation/{task.replace('.json', '.txt')}\"):\n",
    "    #     continue\n",
    "    prompt, output = task_to_prompt(\"data/evaluation/\" + task)\n",
    "    print(f\"{task}\", end=\" \")\n",
    "    full_prompt = f\"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
    "    output = generate_response(full_prompt, model=model, tokenizer=tokenizer, max_new_tokens=2048, temperature=0.5)\n",
    "    with open(f\"basemodel_results/evaluation_with_prompt/{task.replace('.json', '.txt')}\", \"w\") as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9ef4f1bc8e45b2989250e6842d9223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac3c8326e19457cbe0743e71bfd40e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5bd6f4ac.json token length: 1748\n",
      "9aec4887.json token length: 3536\n",
      "cdecee7f.json token length: 1691\n",
      "ba26e723.json token length: 1655\n",
      "aabf363d.json token length: 1130\n",
      "e98196ab.json token length: 2357\n",
      "9172f3a0.json token length: 962\n",
      "23b5c85d.json token length: 4868\n",
      "beb8660c.json token length: 1316\n",
      "cbded52d.json token length: 1754\n",
      "d90796e8.json token length: 1199\n",
      "1f876c06.json token length: 2510\n",
      "e8593010.json token length: 2510\n",
      "56dc2b01.json token length: 2030\n",
      "673ef223.json token length: 4478\n",
      "3e980e27.json token length: 4988\n",
      "272f95fa.json token length: 4220\n",
      "a85d4709.json token length: 668\n",
      "f2829549.json token length: 1124\n",
      "f76d97a5.json token length: 839\n",
      "be94b721.json token length: 1595\n",
      "1190e5a7.json token length: 5219\n",
      "b60334d2.json token length: 1610\n",
      "1bfc4729.json token length: 1895\n",
      "c444b776.json token length: 5240\n",
      "62c24649.json token length: 842\n",
      "6ecd11f4.json token length: 7202\n",
      "fafffa47.json token length: 899\n",
      "aba27056.json token length: 1706\n",
      "045e512c.json Input too long:  9671\n",
      "28e73c20.json token length: 4976\n",
      "c59eb873.json token length: 920\n",
      "e509e548.json token length: 5144\n",
      "d5d6de2d.json token length: 3260\n",
      "97999447.json token length: 2162\n",
      "4347f46a.json token length: 4235\n",
      "ae3edfdc.json token length: 5135\n",
      "3f7978a0.json token length: 2195\n",
      "b782dc8a.json token length: 3746\n",
      "c3e719e8.json token length: 1247\n",
      "d4f3cd78.json token length: 1895\n",
      "5c0a986e.json token length: 2510\n",
      "22eb0ac0.json token length: 2510\n",
      "44f52bb0.json token length: 662\n",
      "50846271.json Input too long:  9563\n",
      "cf98881b.json token length: 1688\n",
      "bc1d5164.json token length: 1205\n",
      "39a8645d.json token length: 2843\n",
      "77fdfe62.json token length: 1310\n",
      "e48d4e1a.json token length: 3125\n",
      "88a62173.json token length: 746\n",
      "d22278a0.json token length: 4064\n",
      "b91ae062.json token length: 1736\n",
      "f1cefba8.json token length: 6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5614dbcf.json token length: 1178\n",
      "eb5a1d5d.json token length: 7664\n",
      "67a3c6ac.json token length: 1043\n",
      "8be77c9e.json token length: 680\n",
      "6a1e5592.json token length: 2645\n",
      "ed36ccf7.json token length: 668\n",
      "72ca375d.json token length: 1670\n",
      "dc0a314f.json token length: 3707\n",
      "68b16354.json token length: 1151\n",
      "6fa7a44f.json token length: 776\n",
      "b94a9452.json token length: 2438\n",
      "dc433765.json token length: 2801\n",
      "91413438.json token length: 2882\n",
      "3631a71a.json Input too long:  24725\n",
      "8f2ea7aa.json token length: 2111\n",
      "6b9890af.json token length: 6812\n",
      "60b61512.json token length: 1610\n",
      "90c28cc7.json token length: 5759\n",
      "1f0c79e5.json token length: 2612\n",
      "11852cab.json token length: 2510\n",
      "09629e4f.json token length: 3692\n",
      "98cf29f8.json token length: 5564\n",
      "a740d043.json token length: 959\n",
      "963e52fc.json token length: 1490\n",
      "0a938d79.json token length: 6122\n",
      "67e8384a.json token length: 992\n",
      "47c1f68c.json token length: 2270\n",
      "ce22a75a.json token length: 1610\n",
      "c909285e.json Input too long:  8687\n",
      "d511f180.json token length: 716\n",
      "868de0fa.json token length: 7316\n",
      "b0c4d837.json token length: 1934\n",
      "a8c38be5.json token length: 2861\n",
      "2c608aff.json token length: 5510\n",
      "22168020.json token length: 2510\n",
      "a87f7484.json token length: 1100\n",
      "8e5a5113.json token length: 1103\n",
      "5daaa586.json token length: 4538\n",
      "6e19193c.json token length: 1895\n",
      "caa06a1f.json token length: 2708\n",
      "d687bc17.json token length: 3812\n",
      "6150a2bd.json token length: 530\n",
      "ae4f1146.json token length: 1748\n",
      "95990924.json token length: 3635\n",
      "a61f2674.json token length: 1610\n",
      "4938f0c2.json token length: 6374\n",
      "d13f3404.json token length: 842\n",
      "9af7a82c.json token length: 839\n",
      "48d8fb45.json token length: 1691\n",
      "0e206a2e.json token length: 5894\n",
      "7ddcd7ec.json token length: 2510\n",
      "42a50994.json token length: 5663\n",
      "ef135b50.json token length: 2510\n",
      "3906de3d.json token length: 2510\n",
      "810b9b61.json token length: 4028\n",
      "82819916.json token length: 2669\n",
      "952a094c.json token length: 2510\n",
      "ea32f347.json token length: 3125\n",
      "f8a8fe49.json token length: 5135\n",
      "0520fde7.json token length: 743\n",
      "e9614598.json token length: 2027\n",
      "27a28665.json token length: 707\n",
      "9ecd008a.json token length: 3563\n",
      "bd4472b8.json token length: 1046\n",
      "67385a82.json token length: 974\n",
      "67a423a3.json token length: 1538\n",
      "b6afb2da.json token length: 1895\n",
      "d6ad076f.json token length: 2510\n",
      "1e0a9b12.json token length: 947\n",
      "46442a0e.json token length: 767\n",
      "9dfd6313.json token length: 818\n",
      "dbc1a6ce.json token length: 4118\n",
      "846bdb03.json token length: 3434\n",
      "9d9215db.json token length: 7991\n",
      "d4469b4b.json token length: 1259\n",
      "a3df8b1e.json token length: 1100\n",
      "28bf18c6.json token length: 1340\n",
      "83302e8f.json Input too long:  13265\n",
      "253bf280.json token length: 4553\n",
      "928ad970.json token length: 4451\n",
      "2bcee788.json token length: 3125\n",
      "a3325580.json token length: 2723\n",
      "137eaa0f.json token length: 1943\n",
      "36d67576.json token length: 4082\n",
      "10fcaaa3.json token length: 1280\n",
      "22233c11.json token length: 2510\n",
      "a5f85a15.json token length: 1496\n",
      "ecdecbb3.json token length: 5021\n",
      "2013d3e2.json token length: 1349\n",
      "3345333e.json token length: 4235\n",
      "e179c5f4.json token length: 1100\n",
      "a68b268e.json token length: 2444\n",
      "1fad071e.json token length: 1427\n",
      "0962bcdd.json token length: 2555\n",
      "f9012d9b.json token length: 854\n",
      "469497ad.json token length: 2885\n",
      "4290ef0e.json token length: 4757\n",
      "855e0971.json token length: 6422\n",
      "e26a3af2.json token length: 4763\n",
      "80af3007.json token length: 4700\n",
      "3befdf3e.json token length: 2642\n",
      "d4a91cb9.json token length: 2918\n",
      "c1d99e64.json token length: 6341\n",
      "af902bf9.json token length: 2510\n",
      "264363fd.json Input too long:  19310\n",
      "d0f5fe59.json token length: 2237\n",
      "ddf7fa4f.json token length: 2510\n",
      "d8c310e9.json token length: 1985\n",
      "1e32b0e9.json token length: 6479\n",
      "d9fac9be.json token length: 1886\n",
      "913fb3ed.json token length: 4025\n",
      "b8825c91.json token length: 7337\n",
      "a61ba2ce.json token length: 2012\n",
      "25d8a9c8.json token length: 668\n",
      "6c434453.json token length: 1895\n",
      "d631b094.json token length: 590\n",
      "97a05b5b.json token length: 4703\n",
      "91714a58.json token length: 5786\n",
      "dae9d2b5.json token length: 899\n",
      "7447852a.json token length: 1409\n",
      "85c4e7cd.json token length: 3077\n",
      "2bee17df.json token length: 3326\n",
      "1f642eb9.json token length: 2510\n",
      "4258a5f9.json token length: 1610\n",
      "445eab21.json token length: 1646\n",
      "40853293.json token length: 6395\n",
      "54d9e175.json token length: 1712\n",
      "8eb1be9a.json token length: 3371\n",
      "7b7f7511.json token length: 761\n",
      "3aa6fb7a.json token length: 1130\n",
      "7468f01a.json token length: 3311\n",
      "53b68214.json token length: 2120\n",
      "b527c5c6.json Input too long:  9425\n",
      "5117e062.json token length: 2519\n",
      "995c5fa3.json token length: 1373\n",
      "29623171.json token length: 2951\n",
      "7c008303.json token length: 1706\n",
      "b230c067.json token length: 1895\n",
      "3618c87e.json token length: 935\n",
      "5582e5ca.json token length: 599\n",
      "d06dbe63.json token length: 2930\n",
      "fcb5c309.json token length: 3548\n",
      "57aa92db.json Input too long:  8471\n",
      "6cdd2623.json token length: 5864\n",
      "4093f84a.json token length: 4526\n",
      "760b3cac.json token length: 1544\n",
      "3eda0437.json token length: 2453\n",
      "d364b489.json token length: 1895\n",
      "6d58a25d.json Input too long:  8810\n",
      "06df4c85.json Input too long:  11186\n",
      "54d82841.json token length: 1385\n",
      "a1570a43.json token length: 2417\n",
      "1c786137.json token length: 4646\n",
      "b9b7f026.json token length: 3215\n",
      "3bdb4ada.json token length: 3455\n",
      "623ea044.json token length: 4271\n",
      "75b8110e.json token length: 1832\n",
      "00d62c1b.json token length: 6056\n",
      "1a07d186.json token length: 6644\n",
      "2dc579da.json token length: 1616\n",
      "4522001f.json token length: 962\n",
      "0b148d64.json token length: 5144\n",
      "444801d8.json token length: 2510\n",
      "543a7ed5.json token length: 3770\n",
      "4612dd53.json token length: 3491\n",
      "7fe24cdd.json token length: 842\n",
      "bdad9b1f.json token length: 935\n",
      "d2abd087.json token length: 2510\n",
      "508bd3b6.json token length: 3434\n",
      "73251a56.json Input too long:  9671\n",
      "41e4d17e.json token length: 3770\n",
      "bb43febb.json token length: 1895\n",
      "4c4377d9.json token length: 893\n",
      "b27ca6d3.json token length: 4271\n",
      "c9f8e694.json token length: 2555\n",
      "e9afcf9a.json token length: 575\n",
      "88a10436.json token length: 2042\n",
      "ff805c23.json token length: 7547\n",
      "93b581b8.json token length: 1166\n",
      "e76a88a6.json token length: 1895\n",
      "496994bd.json token length: 1055\n",
      "9f236235.json token length: 4649\n",
      "23581191.json token length: 1610\n",
      "cce03e0d.json token length: 1247\n",
      "e40b9e2f.json token length: 2510\n",
      "d07ae81c.json token length: 5105\n",
      "7837ac64.json Input too long:  12476\n",
      "a416b8f3.json token length: 803\n",
      "017c7c7b.json token length: 869\n",
      "a5313dff.json token length: 2285\n",
      "780d0b14.json token length: 5951\n",
      "6aa20dc0.json Input too long:  9434\n",
      "a78176bb.json token length: 2510\n",
      "d10ecb37.json token length: 1058\n",
      "5ad4f10b.json token length: 6821\n",
      "4c5c2cf0.json token length: 4301\n",
      "25d487eb.json token length: 3782\n",
      "feca6190.json token length: 2330\n",
      "228f6490.json token length: 2510\n",
      "56ff96f3.json token length: 2573\n",
      "50cb2852.json token length: 3854\n",
      "1cf80156.json token length: 2168\n",
      "746b3537.json token length: 794\n",
      "3de23699.json token length: 3290\n",
      "32597951.json token length: 6479\n",
      "c9e6f938.json token length: 680\n",
      "d43fd935.json token length: 2510\n",
      "a9f96cdd.json token length: 830\n",
      "a65b410d.json token length: 1757\n",
      "a699fb00.json token length: 2060\n",
      "2dee498d.json token length: 983\n",
      "ec883f72.json token length: 2807\n",
      "94f9d214.json token length: 1097\n",
      "d037b0a7.json token length: 599\n",
      "ce4f8723.json token length: 1157\n",
      "f8ff0b80.json token length: 2165\n",
      "e73095fd.json token length: 5420\n",
      "6d0aefbc.json token length: 776\n",
      "3af2c5a8.json token length: 986\n",
      "3bd67248.json token length: 2408\n",
      "e6721834.json token length: 5279\n",
      "9565186b.json token length: 668\n",
      "321b1fc6.json token length: 1895\n",
      "2281f1f4.json token length: 2510\n",
      "c0f76784.json token length: 3434\n",
      "3ac3eb23.json token length: 1223\n",
      "6430c8c4.json token length: 1157\n",
      "f15e1fac.json token length: 3950\n",
      "025d127b.json token length: 1883\n",
      "7df24a62.json Input too long:  14708\n",
      "ea786f4a.json token length: 1271\n",
      "ce602527.json token length: 5180\n",
      "8d510a79.json token length: 1895\n",
      "6455b5f5.json token length: 5807\n",
      "7b6016b9.json Input too long:  11558\n",
      "f25ffba3.json token length: 995\n",
      "05269061.json token length: 1439\n",
      "29ec7d0e.json Input too long:  9173\n",
      "39e1d7f9.json Input too long:  15137\n",
      "8e1813be.json token length: 3278\n",
      "db3e9e38.json token length: 1184\n",
      "d406998b.json token length: 1460\n",
      "f5b8619d.json token length: 1193\n",
      "363442ee.json token length: 2867\n",
      "a79310a0.json token length: 839\n",
      "3c9b0459.json token length: 668\n",
      "0ca9ddb6.json token length: 2111\n",
      "bbc9ae5d.json token length: 992\n",
      "c3f564a4.json token length: 5786\n",
      "05f2a901.json token length: 2696\n",
      "44d8ac46.json token length: 4313\n",
      "63613498.json token length: 2510\n",
      "74dd1130.json token length: 668\n",
      "31aa019c.json token length: 2510\n",
      "d9f24cd1.json token length: 1895\n",
      "99b1bc43.json token length: 1157\n",
      "e50d258f.json token length: 1769\n",
      "662c240a.json token length: 938\n",
      "dc1df850.json token length: 1364\n",
      "b7249182.json token length: 3623\n",
      "5521c0d9.json token length: 5135\n",
      "5168d44c.json token length: 2153\n",
      "6773b310.json token length: 2348\n",
      "e8dc4411.json token length: 4604\n",
      "776ffc46.json Input too long:  11225\n",
      "bda2d7a6.json token length: 1334\n",
      "f8c80d96.json token length: 2510\n",
      "0d3d703e.json token length: 668\n",
      "9edfc990.json token length: 5078\n",
      "fcc82909.json token length: 2510\n",
      "6855a6e4.json token length: 5135\n",
      "f35d900a.json token length: 7211\n",
      "08ed6ac7.json token length: 1610\n",
      "99fa7670.json token length: 1289\n",
      "db93a21d.json Input too long:  9875\n",
      "eb281b96.json token length: 2129\n",
      "890034e9.json Input too long:  9671\n",
      "c8cbb738.json token length: 2753\n",
      "29c11459.json token length: 1220\n",
      "3428a4f5.json token length: 1760\n",
      "8403a5d5.json token length: 2510\n",
      "539a4f51.json token length: 1610\n",
      "2204b7a8.json token length: 2510\n",
      "6d0160f0.json token length: 3692\n",
      "239be575.json token length: 1283\n",
      "46f33fce.json token length: 5210\n",
      "a8d7556c.json token length: 7214\n",
      "ba97ae07.json token length: 2639\n",
      "e21d9049.json token length: 3647\n",
      "1b2d62fb.json token length: 1295\n",
      "1b60fb0c.json token length: 2510\n",
      "b190f7f5.json token length: 1964\n",
      "8731374e.json token length: 5771\n",
      "6f8cd79b.json token length: 977\n",
      "6e82a1ae.json token length: 2510\n",
      "49d1d64f.json token length: 668\n",
      "0dfd9992.json Input too long:  9671\n",
      "d89b689b.json token length: 2510\n",
      "d23f8c26.json token length: 911\n",
      "b1948b0a.json token length: 782\n",
      "f25fbde4.json token length: 1778\n",
      "e5062a87.json token length: 2510\n",
      "8d5021e8.json token length: 806\n",
      "b8cdaf2b.json token length: 1316\n",
      "72322fa7.json token length: 5741\n",
      "c8f0f002.json token length: 725\n",
      "834ec97d.json token length: 1532\n",
      "8a004b2b.json token length: 4973\n",
      "2dd70a9a.json token length: 5267\n",
      "25ff71a9.json token length: 668\n",
      "b548a754.json token length: 3305\n",
      "ff28f65a.json token length: 1682\n",
      "5c2c9af4.json Input too long:  12284\n",
      "6e02f1e3.json token length: 737\n",
      "794b24be.json token length: 1082\n",
      "aedd82e4.json token length: 809\n",
      "f8b3ba0a.json token length: 3074\n",
      "a2fd1cf0.json token length: 4232\n",
      "ded97339.json token length: 2510\n",
      "a64e4611.json Input too long:  19310\n",
      "234bbc79.json token length: 1199\n",
      "ac0a08a4.json token length: 1544\n",
      "178fcbfb.json token length: 2432\n",
      "941d9a10.json token length: 2510\n",
      "90f3ed37.json token length: 3560\n",
      "de1cd16c.json token length: 4574\n",
      "150deff5.json token length: 2180\n",
      "36fdfd69.json token length: 5864\n",
      "ce9e57f2.json token length: 2003\n",
      "a48eeaf7.json token length: 1895\n",
      "007bbfb7.json token length: 1817\n",
      "7f4411dc.json token length: 3752\n",
      "8efcae92.json token length: 5798\n",
      "b775ac94.json Input too long:  11114\n",
      "6d75e8bb.json token length: 2315\n",
      "7e0986d6.json token length: 3347\n",
      "1f85a75f.json Input too long:  8567\n",
      "681b3aeb.json token length: 1691\n",
      "e3497940.json token length: 1850\n",
      "484b58aa.json Input too long:  18071\n",
      "694f12f3.json token length: 1895\n",
      "6cf79266.json Input too long:  8810\n",
      "b2862040.json token length: 4727\n",
      "447fd412.json token length: 4505\n",
      "4be741c5.json token length: 2186\n",
      "1caeab9d.json token length: 1910\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "model, tokenizer = create_model(use_finetuned=False)\n",
    "\n",
    "for task in tqdm(os.listdir(\"data/training\")):\n",
    "    # if os.path.exists(f\"basemodel_results/training/{task.replace('.json', '.txt')}\"):\n",
    "    #     continue\n",
    "    prompt, output = task_to_prompt(\"data/training/\" + task)\n",
    "    print(f\"{task}\", end=\" \")\n",
    "    full_prompt = f\"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
    "    output = generate_response(full_prompt, model=model, tokenizer=tokenizer, max_new_tokens=2048, temperature=0.5)\n",
    "    with open(f\"basemodel_results/training_with_prompt/{task.replace('.json', '.txt')}\", \"w\") as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Concept ARC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5de452909714d9ba769e5be7f9ea6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af011f1438048d59d15c281057a83a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtendToBoundary2.json token length: 5220\n",
      "ExtendToBoundary6.json token length: 2199\n",
      "ExtendToBoundary3.json token length: 2550\n",
      "ExtendToBoundary7.json token length: 1749\n",
      "ExtendToBoundary9.json token length: 4809\n",
      "ExtendToBoundary1.json token length: 1353\n",
      "ExtendToBoundary5.json token length: 1476\n",
      "ExtendToBoundary10.json token length: 2097\n",
      "ExtendToBoundary4.json token length: 1059\n",
      "ExtendToBoundary8.json token length: 2583\n",
      "ExtendToBoundaryMinimal.json token length: 1059\n",
      "MoveToBoundary8.json token length: 2901\n",
      "MoveToBoundary10.json token length: 1827\n",
      "MoveToBoundary4.json token length: 1557\n",
      "MoveToBoundary5.json token length: 1557\n",
      "MoveToBoundary1.json token length: 1305\n",
      "MoveToBoundary9.json token length: 2025\n",
      "MoveToBoundary7.json token length: 2565\n",
      "MoveToBoundary3.json token length: 1557\n",
      "MoveToBoundary6.json token length: 1059\n",
      "MoveToBoundary2.json token length: 2172\n",
      "MoveToBoundaryMinimal.json token length: 1557\n",
      "ExtractObjects7.json token length: 1182\n",
      "ExtractObjects3.json token length: 2160\n",
      "ExtractObjects6.json token length: 1254\n",
      "ExtractObjects2.json token length: 2481\n",
      "ExtractObjects4.json token length: 1812\n",
      "ExtractObjects8.json token length: 1101\n",
      "ExtractObjects10.json token length: 1359\n",
      "ExtractObjects9.json token length: 1443\n",
      "ExtractObjects5.json token length: 2367\n",
      "ExtractObjectsMinimal.json token length: 1614\n",
      "ExtractObjects1.json token length: 1437\n",
      "HorizontalVertical10.json token length: 1557\n",
      "HorizontalVertical7.json token length: 2172\n",
      "HorizontalVertical3.json token length: 3024\n",
      "HorizontalVertical6.json token length: 4188\n",
      "HorizontalVertical2.json token length: 2433\n",
      "HorizontalVertical4.json token length: 4167\n",
      "HorizontalVertical8.json token length: 4680\n",
      "HorizontalVerticalMinimal.json token length: 1740\n",
      "HorizontalVertical9.json token length: 597\n",
      "HorizontalVertical5.json token length: 2172\n",
      "HorizontalVertical1.json token length: 2805\n",
      "InsideOutside6.json token length: 2874\n",
      "InsideOutside2.json token length: 2787\n",
      "InsideOutside7.json token length: 1194\n",
      "InsideOutside3.json token length: 2787\n",
      "InsideOutsideMinimal.json token length: 2172\n",
      "InsideOutside9.json token length: 1317\n",
      "InsideOutside10.json token length: 2217\n",
      "InsideOutside5.json token length: 4923\n",
      "InsideOutside1.json token length: 1296\n",
      "InsideOutside4.json token length: 5211\n",
      "InsideOutside8.json token length: 1938\n",
      "Count5.json token length: 693\n",
      "Count1.json token length: 1314\n",
      "Count9.json token length: 1197\n",
      "Count8.json token length: 1416\n",
      "Count4.json token length: 1518\n",
      "Count6.json token length: 1437\n",
      "Count2.json token length: 3324\n",
      "Count7.json token length: 1419\n",
      "Count10.json token length: 1062\n",
      "Count3.json token length: 1530\n",
      "CountMinimal.json token length: 531\n",
      "CleanUp4.json token length: 3489\n",
      "CleanUpMinimal.json token length: 1245\n",
      "CleanUp8.json token length: 1557\n",
      "CleanUp9.json token length: 597\n",
      "CleanUp5.json token length: 2001\n",
      "CleanUp1.json token length: 1740\n",
      "CleanUp7.json token length: 1773\n",
      "CleanUp3.json token length: 2697\n",
      "CleanUp10.json token length: 597\n",
      "CleanUp6.json token length: 1857\n",
      "CleanUp2.json token length: 1464\n",
      "AboveBelow10.json token length: 1890\n",
      "AboveBelow7.json token length: 2325\n",
      "AboveBelow3.json token length: 1635\n",
      "AboveBelow6.json token length: 1533\n",
      "AboveBelowMinimal.json token length: 786\n",
      "AboveBelow2.json token length: 5082\n",
      "AboveBelow8.json token length: 2712\n",
      "AboveBelow4.json token length: 1629\n",
      "AboveBelow5.json token length: 1221\n",
      "AboveBelow1.json token length: 3108\n",
      "AboveBelow9.json token length: 2487\n",
      "Order1.json token length: 2937\n",
      "Order5.json token length: 1947\n",
      "Order9.json token length: 867\n",
      "Order8.json token length: 897\n",
      "Order4.json token length: 1617\n",
      "Order2.json token length: 1617\n",
      "Order6.json token length: 1689\n",
      "OrderMinimal.json token length: 828\n",
      "Order3.json token length: 1191\n",
      "Order7.json token length: 2718\n",
      "Order10.json token length: 1782\n",
      "TopBottom3D1.json token length: 1416\n",
      "TopBottom3D5.json token length: 1458\n",
      "TopBottom3D9.json token length: 2940\n",
      "TopBottom3D10.json token length: 3078\n",
      "TopBottom3D8.json token length: 1059\n",
      "TopBottom3D4.json token length: 1815\n",
      "TopBottom3D2.json token length: 1101\n",
      "TopBottom3D6.json token length: 594\n",
      "TopBottom3DMinimal.json token length: 1017\n",
      "TopBottom3D3.json token length: 1416\n",
      "TopBottom3D7.json token length: 2256\n",
      "Copy4.json token length: 3096\n",
      "Copy8.json token length: 2403\n",
      "Copy10.json token length: 2733\n",
      "Copy9.json token length: 2214\n",
      "Copy1.json token length: 495\n",
      "Copy5.json token length: 681\n",
      "Copy3.json token length: 2643\n",
      "Copy7.json token length: 1305\n",
      "Copy2.json token length: 2265\n",
      "CopyMinimal.json token length: 510\n",
      "Copy6.json token length: 846\n",
      "CompleteShape8.json token length: 1557\n",
      "CompleteShape4.json token length: 1557\n",
      "CompleteShape5.json token length: 597\n",
      "CompleteShape10.json token length: 3783\n",
      "CompleteShape1.json token length: 1425\n",
      "CompleteShapeMinimal.json token length: 1467\n",
      "CompleteShape9.json token length: 2181\n",
      "CompleteShape7.json token length: 597\n",
      "CompleteShape3.json token length: 1557\n",
      "CompleteShape6.json token length: 597\n",
      "CompleteShape2.json token length: 990\n",
      "SameDifferent2.json token length: 2709\n",
      "SameDifferent6.json token length: 2580\n",
      "SameDifferent3.json token length: 1968\n",
      "SameDifferent7.json token length: 3339\n",
      "SameDifferent1.json token length: 1905\n",
      "SameDifferent5.json token length: 1632\n",
      "SameDifferent10.json token length: 2781\n",
      "SameDifferent9.json token length: 2787\n",
      "SameDifferent8.json token length: 1770\n",
      "SameDifferentMinimal.json token length: 2787\n",
      "SameDifferent4.json token length: 1557\n",
      "Center7.json token length: 525\n",
      "Center3.json token length: 2808\n",
      "Center6.json token length: 3807\n",
      "Center2.json token length: 153\n",
      "Center10.json token length: 1095\n",
      "Center8.json token length: 2784\n",
      "Center4.json token length: 1053\n",
      "CenterMinimal.json token length: 981\n",
      "Center5.json token length: 2019\n",
      "Center1.json token length: 1314\n",
      "Center9.json token length: 1497\n",
      "FilledNotFilled6.json token length: 1398\n",
      "FilledNotFilled2.json token length: 1383\n",
      "FilledNotFilledMinimal.json token length: 1416\n",
      "FilledNotFilled7.json token length: 2214\n",
      "FilledNotFilled3.json token length: 1290\n",
      "FilledNotFilled9.json token length: 3549\n",
      "FilledNotFilled5.json token length: 1665\n",
      "FilledNotFilled1.json token length: 1281\n",
      "FilledNotFilled10.json token length: 3819\n",
      "FilledNotFilled4.json token length: 3039\n",
      "FilledNotFilled8.json token length: 2019\n",
      "TopBottom2D2.json token length: 885\n",
      "TopBottom2D6.json token length: 849\n",
      "TopBottom2D3.json token length: 1683\n",
      "TopBottom2DMinimal.json token length: 828\n",
      "TopBottom2D7.json token length: 1314\n",
      "TopBottom2D9.json token length: 1059\n",
      "TopBottom2D1.json token length: 1194\n",
      "TopBottom2D5.json token length: 2172\n",
      "TopBottom2D10.json token length: 1539\n",
      "TopBottom2D4.json token length: 2862\n",
      "TopBottom2D8.json token length: 2172\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "model, tokenizer = create_model(use_finetuned=False)\n",
    "\n",
    "for subdir, dirs, files in tqdm(os.walk(\"data/ConceptARC/\")):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            if os.path.exists(f\"basemodel_results/ConceptARC/{file.replace('.json', '.txt')}\"):\n",
    "                continue\n",
    "            concepts = subdir.replace('data', 'basemodel_results')\n",
    "            if not os.path.exists(concepts):\n",
    "                os.mkdir(concepts)\n",
    "            prompt, output = task_to_prompt(os.path.join(subdir, file))\n",
    "            print(f\"{file}\", end=\" \")\n",
    "            full_prompt = f\"GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\"\n",
    "            output = generate_response(full_prompt, model=model, tokenizer=tokenizer, max_new_tokens=2048, temperature=0.5)\n",
    "            with open(f\"{concepts}/{file.replace('.json', '.txt')}\", \"w\") as f:\n",
    "                f.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
